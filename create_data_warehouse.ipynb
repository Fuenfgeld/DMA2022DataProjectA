{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In diesem Notebook wird unser Datawarehouse erstellt. Wir lesen die Daten aus den CSV-Dateien ein und wandeln die so erstellten Tabellen in ein Sternschema um."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importieren der von uns benötigten Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import logging\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging konfigurieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"Logs/log.txt\", level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen einer Verbindung zur Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "#connect to DB\n",
    "conn = sqlite3.connect('datawarehouse.db')\n",
    "cursor = conn.cursor()\n",
    "logging.debug(\" \"+str(datetime.datetime.now()) + \" create_data_warehouse.ipynb opened a connection to the database\")\n",
    "print(\"Opened database successfully\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mithilfe von Pandas CSV-Dateien einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load CSVs\n",
    "# careplans = pd.read_csv('Daten/careplans.csv', sep=\",\")\n",
    "# conditions = pd.read_csv('Daten/conditions.csv', sep=\",\")\n",
    "# disease = pd.read_csv('Daten/disease.csv', sep=\",\")\n",
    "# immunizations = pd.read_csv('Daten/immunizations.csv', sep=\",\")\n",
    "# medications = pd.read_csv('Daten/medications.csv', sep=\",\")\n",
    "# observations = pd.read_csv('Daten/observations.csv', sep=\",\")\n",
    "# patients = pd.read_csv('Daten/patients.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load CSVs\n",
    "careplans = pd.read_csv('Daten/neue_Daten/careplans.csv', sep=\",\")\n",
    "conditions = pd.read_csv('Daten/neue_Daten/conditions.csv', sep=\",\")\n",
    "#disease = pd.read_csv('Daten/neue_Daten/disease.csv', sep=\",\")\n",
    "immunizations = pd.read_csv('Daten/neue_Daten/immunizations.csv', sep=\",\")\n",
    "medications = pd.read_csv('Daten/neue_Daten/medications.csv', sep=\",\")\n",
    "observations = pd.read_csv('Daten/neue_Daten/observations.csv', sep=\",\")\n",
    "patients = pd.read_csv('Daten/neue_Daten/patients.csv', sep=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenverschleierung \n",
    "Für die Verschleierung der Daten wird aus den Werten mit, denen es möglich ist eine Person zu identifizieren ein Hash gebildet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_anonymize =  (\"SSN\",\"DRIVERS\",\"PASSPORT\",\"FIRST\", \"LAST\",\"MAIDEN\", \"ADDRESS\", \"LAT\", \"LON\", \"BIRTHPLACE\")\n",
    "for idx in to_anonymize: \n",
    "    patients[idx] = patients[idx].apply(lambda x: hash(x) if(pd.isna(x) == False) else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorhandene Tabellen löschen, um Konflikte zu vermeiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete Tables in case they exist\n",
    "cursor.execute(\"DROP TABLE IF EXISTS careplans\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS conditions\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS disease\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS immunizations\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS medications\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS observations\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS patients\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS facts_table\")\n",
    "logging.debug(\" \"+str(datetime.datetime.now()) + \" create_data_warehouse.ipyn dropped existing tables in the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen der Tabellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Tables\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS careplans (\n",
    "                           Id STRING PRIMARY KEY,\n",
    "                           START DATE,\n",
    "                           STOP DATE,\n",
    "                           PATIENT STRING,\n",
    "                           ENCOUNTER STRING,\n",
    "                           CODE STRING,\n",
    "                           DESCRIPTION STRING,\n",
    "                           REASONCODE STRING,\n",
    "                           REASONDESCRIPTION STRING,\n",
    "                           FOREIGN KEY (PATIENT)\n",
    "                              REFERENCES patients (Id) \n",
    "                           FOREIGN KEY (Encounter)\n",
    "                              REFERENCES encounters (Id) \n",
    "                       )\n",
    "                       ''')\n",
    "\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS conditions (\n",
    "                           condition_code INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                           START DATE,\n",
    "                           STOP DATE,\n",
    "                           PATIENT STRING,\n",
    "                           ENCOUNTER STRING,\n",
    "                           CODE STRING,\n",
    "                           DESCRIPTION STRING,\n",
    "                           FOREIGN KEY (PATIENT)\n",
    "                              REFERENCES patients (Id) \n",
    "                           FOREIGN KEY (Encounter)\n",
    "                              REFERENCES encounters (Id) \n",
    "                        )\n",
    "                       ''')\n",
    "\n",
    "\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS observations (\n",
    "                           observation_code INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                           DATE DATE,\n",
    "                           PATIENT STRING,\n",
    "                           ENCOUNTER STRING,\n",
    "                           CODE STRING,\n",
    "                           DESCRIPTION STRING,\n",
    "                           VALUE STRING,\n",
    "                           UNITS STRING,\n",
    "                           TYPE STRING,\n",
    "                           FOREIGN KEY (PATIENT)\n",
    "                              REFERENCES patients (Id) \n",
    "                           FOREIGN KEY (Encounter)\n",
    "                              REFERENCES encounters (Id) \n",
    "\n",
    "                       )\n",
    "                       ''')\n",
    "\n",
    "\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS patients (\n",
    "                           Id STRING PRIMARY KEY,\n",
    "                           BIRTHDATE DATE,\n",
    "                           DEATHDATE DATE,\n",
    "                           SSN STRING,\n",
    "                           DRIVERS STRING,\n",
    "                           PASSPORT STRING,\n",
    "                           PREFIX STRING,\n",
    "                           FIRST STRING,\n",
    "                           LAST STRING,\n",
    "                           SUFFIX STRING,\n",
    "                           MAIDEN STRING,\n",
    "                           MARITAL STRING,\n",
    "                           RACE STRING,\n",
    "                           ETHNICITY STRING,\n",
    "                           GENDER STRING,\n",
    "                           BIRTHPLACE STRING,\n",
    "                           ADDRESS STRING,\n",
    "                           CITY STRING,\n",
    "                           STATE STRING,\n",
    "                           COUNTY STRING,\n",
    "                           ZIP STRING,\n",
    "                           LAT INTEGER,\n",
    "                           LON INTEGER,\n",
    "                           HEALTHCARE_EXPENSES INTEGER,\n",
    "                           HEALTHCARE_COVERAGE INTEGER\n",
    "                       )\n",
    "                       ''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS immunizations(\n",
    "                           immunization_code INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                           DATE DATE,\n",
    "                           PATIENT STRING,\n",
    "                           ENCOUNTER STRING,\n",
    "                           CODE STRING,\n",
    "                           DESCRIPTION STRING,\n",
    "                           BASE_COST INTEGER,\n",
    "                           FOREIGN KEY (PATIENT)\n",
    "                              REFERENCES patients (Id) \n",
    "                           FOREIGN KEY (Encounter)\n",
    "                              REFERENCES encounters (Id) \n",
    "\n",
    "                       )\n",
    "                       ''')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logging.debug(\" \"+str(datetime.datetime.now()) + \" create_data_warehouse.ipyn created needed tables in the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Daten aus den Dataframes in die erstellten Tabellen schreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert into table\n",
    "careplans.to_sql('careplans', conn, if_exists='append', index=False)\n",
    "conditions.to_sql('conditions', conn, if_exists='append', index=False)\n",
    "immunizations.to_sql('immunizations', conn, if_exists='append', index=False)\n",
    "medications.to_sql('medications', conn, if_exists='append', index=False)\n",
    "observations.to_sql('observations', conn, if_exists='append', index=False)\n",
    "patients.to_sql('patients', conn, if_exists='append', index=False)\n",
    "\n",
    "logging.debug(\" \"+str(datetime.datetime.now()) + \" create_data_warehouse.ipyn wrote data from csvs into the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sternschema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Grund für die Verwendung eines Sternschemas liegt darin, die Anzahl der Join-Bedingungnen für die Auswertung der einzelnen Tabellen zu reduzieren. bei dem Sternschema wird eine Zentrale Datenbank erzeugt, welche die relevanten Daten enthält. Um den Kern des Sternschemas werden weitere Dimensions Tabellen angeordnet. Wichtig dabei kann es zu duplizierungen der Daten in kommen.  Das Sternschema erlaubt uns, uns die Tabellen passende für unsere Forschungsfrage zusammenzujoinen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faktentabelle erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Faktentabelle enthält die Primary Keys aus allen anderen Tabellen. Zusätzlich werden die Attribute VALUE, START_DATE und STOP_DATE hinzugefügt. VALUE enthält hierbei entweder den CODE oder den VALUE der Tabelle aus der die Daten stammen. Das Selbe gilt für START_DATE und STOP_DATE. Gibt es in der ursprünglichen Tabelle nur ein DATE und kein START_DATE und STOP_DATE wird das Datum als START_DATE übernommen und STOP_DATE bleibt dann leer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE IF NOT EXISTS facts_table (\n",
    "                          patient_ID STRING,\n",
    "                          careplan_ID INT,\n",
    "                          condition_id INT,\n",
    "                          immunization_code INT,\n",
    "                          VALUE STRING,\n",
    "                          START_DATE DATE,\n",
    "                          STOP_DATE DATE,\n",
    "                          observation_code INT, \n",
    "                          FOREIGN KEY (patient_ID)\n",
    "                            REFERENCES patients (Id) \n",
    "                          FOREIGN KEY (careplan_ID)\n",
    "                            REFERENCES careplans (Id) \n",
    "                          FOREIGN KEY (condition_id)\n",
    "                            REFERENCES conditions (condition_code)\n",
    "                          FOREIGN KEY (immunization_code)\n",
    "                            REFERENCES immunizations (immunization_code) \n",
    "                          FOREIGN KEY (observation_code)\n",
    "                            REFERENCES observations (observation_code)                             \n",
    "\n",
    "                       )\n",
    "                       ''')\n",
    "\n",
    "logging.debug(\" \"+str(datetime.datetime.now()) + \" create_data_warehouse.ipyn created the facts_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cid               name    type  notnull dflt_value  pk\n",
      "0    0         patient_ID  STRING        0       None   0\n",
      "1    1        careplan_ID     INT        0       None   0\n",
      "2    2       condition_id     INT        0       None   0\n",
      "3    3  immunization_code     INT        0       None   0\n",
      "4    4              VALUE  STRING        0       None   0\n",
      "5    5         START_DATE    DATE        0       None   0\n",
      "6    6          STOP_DATE    DATE        0       None   0\n",
      "7    7   observation_code     INT        0       None   0\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_sql_query(\"PRAGMA table_info('facts_table')\", conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten in Faktentabelle übertragen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''INSERT INTO facts_table        \n",
    "                    (patient_ID, careplan_ID, VALUE, START_DATE, STOP_DATE) \n",
    "                    SELECT PATIENT, Id, CODE, START, STOP\n",
    "                    FROM careplans\n",
    "                    ;''')\n",
    "\n",
    "\n",
    "\n",
    "cursor.execute('''INSERT INTO facts_table        \n",
    "                    (patient_ID, observation_code, VALUE, START_DATE) \n",
    "                    SELECT PATIENT, CODE, VALUE, DATE \n",
    "                    FROM OBSERVATIONS\n",
    "                    ;''')\n",
    "\n",
    "\n",
    "cursor.execute('''INSERT INTO facts_table        \n",
    "                    (patient_ID, condition_Id, VALUE, START_DATE, STOP_DATE) \n",
    "                    SELECT PATIENT, condition_code, CODE, START, STOP\n",
    "                    FROM conditions\n",
    "                    ;''')\n",
    "\n",
    "cursor.execute('''INSERT INTO facts_table        \n",
    "                    (patient_ID, immunization_code, VALUE, START_DATE) \n",
    "                    SELECT PATIENT, immunization_code, CODE, DATE\n",
    "                    FROM immunizations\n",
    "                    ;''')\n",
    "\n",
    "logging.debug(\" \"+str(datetime.datetime.now()) + \" create_data_warehouse.ipyn wrote data into the facts_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nach dem Bearbeiten müssen wir unsere Anpassungen commiten und die Verbindung zur Datenbank beenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "logging.debug(\" \"+str(datetime.datetime.now()) + \" create_data_warehouse.ipynb commited changes to the database\")\n",
    "conn.close()\n",
    "logging.debug(\" \"+str(datetime.datetime.now()) + \" create_data_warehouse.ipynb closed the connection to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datawarehouse created successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Datawarehouse created successfully\")\n",
    "logging.debug(\" \"+str(datetime.datetime.now()) + \" Datewarehouse was created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dc94f6e0cc27f85cc6c505c3db60229b440618b97049f6dc4bb57773b8bda21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
